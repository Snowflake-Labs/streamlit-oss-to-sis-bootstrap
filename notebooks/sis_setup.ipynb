{
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat_minor": 2,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell1",
    "resultHeight": 256,
    "collapsed": false
   },
   "source": "# Preparing Snowflake\nThis note book will guide you through the required steps thats need to prepare your Snowflake account to deploy the demo [Streamlit ML App](https://github.com/kameshsampath/ks-st-mt-app)\n\nTypically we wil \n\n- [x] Create Schemas and Tables\n- [x] Create a external stage to S3\n- [x] Load Penguins Dataset on the table",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "code",
   "id": "b28d9a98-b375-4db9-8219-0df97eb39f14",
   "metadata": {
    "language": "sql",
    "name": "cell2",
    "collapsed": false,
    "resultHeight": 111
   },
   "outputs": [],
   "source": "-- data schema\ncreate schema if not exists data;\n-- create schema to hold all stages\ncreate schema if not exists stages;\n-- create schema to hold all file formats\ncreate schema if not exists file_formats;\n-- apps to hold all streamlit apps\ncreate schema if not exists apps;\n\ncreate stage if not exists stages.st_ml_app_penguins\n  url='s3://'\n\ncreate file format if not exist file_formats.csv\n  type='csv'\n  SKIP_HEADER=1;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3f387e15-1bfe-46a5-9ed8-7000d75afeef",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "collapsed": false,
    "resultHeight": 495,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\n\ndf = pd.read_csv('https://github.com/dataprofessor/data/blob/master/penguins_cleaned.csv')\ndf",
   "execution_count": null
  }
 ]
}